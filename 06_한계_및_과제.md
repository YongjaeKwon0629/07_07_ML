# 6. 한계 및 과제

머신러닝은 다양한 분야에서 놀라운 성과를 보이고 있지만, 여전히 **기술적 제약, 해석 가능성 문제, 윤리적 우려** 등 여러 한계를 안고 있습니다. 본 문서에서는 머신러닝의 주요 한계와 향후 해결 과제들을 살펴봅니다.

---

## ⚙️ 1. 데이터 품질 및 편향 문제

- **Garbage In, Garbage Out (GIGO)**: 부정확하거나 편향된 데이터는 왜곡된 결과를 낳음
- **데이터 불균형 (Imbalanced Data)**: 소수 클래스의 예측 성능 저하
- **표본 편향 (Sampling Bias)**: 대표성 없는 데이터로 일반화 실패
- **자동화된 편견 (Automated Bias)**: 인종, 성별, 지역에 따른 차별적 의사결정

### 🔎 예시
- 신용 대출 모델이 특정 인종에게 불리한 판단을 내림
- 얼굴 인식 시스템이 특정 인종에 대해 오인식률이 높음

---

## 🧠 2. 해석 가능성 부족 (Black-box 문제)

- 복잡한 모델 (딥러닝 등)은 **결정 기준이 불투명**
- 모델의 예측 결과를 설명하지 못할 경우 신뢰도 저하
- 의료, 금융, 법률 등 고위험 분야에서 **설명 가능성(Explainability)** 필수

### 대안 기술
- SHAP, LIME: 모델의 부분적 설명
- Interpretable Models: 결정 트리, 선형 모델 등

---

## 🧪 3. 과적합 (Overfitting)과 일반화 문제

- 훈련 데이터에 너무 치우쳐 새로운 데이터에 대한 예측력이 떨어짐
- 특히 소규모 데이터, 복잡한 모델에서 자주 발생

### 해결 방법
- 교차 검증
- 정규화(L1, L2), Dropout
- 단순한 모델 사용

---

## 🛠️ 4. 유지보수 및 데이터 드리프트

- 데이터 분포가 시간이 지남에 따라 변함 (Data Drift, Concept Drift)
- 기존 모델 성능 저하 → **지속적인 재학습 필요**
- 모델 운영(MLOps)의 복잡도 증가

---

## 🧮 5. 윤리적·사회적 문제

- **책임 소재 불명확**: 예측 오류 시 책임 주체 모호
- **프라이버시 침해**: 민감 정보의 과도한 활용
- **알고리즘 투명성 부족**: 비공개 모델의 사회적 논란

### 대표 사례
- 채용 자동화 시스템이 특정 성별/인종을 배제
- 보험료 산정 모델이 소득 수준을 차별적으로 반영

---

## 🚧 6. 자원 소모 및 환경 비용

- 대규모 모델 학습 시 GPU, TPU 등 고성능 하드웨어 필요
- 에너지 소비 및 탄소 배출 증가 → 지속 가능성 문제 제기

---

## 🔮 향후 과제

| 분야 | 과제 |
|------|------|
| 기술 | 고성능 + 설명 가능한 모델 개발 |
| 윤리 | 공정성, 프라이버시 보호 알고리즘 |
| 운영 | 자동화된 재학습 파이프라인(MLOps) |
| 법제도 | 알고리즘 책임성과 투명성 확보 |

---

> 📚 전체 문서 완료.  
> 돌아가기: [README.md](./README.md)
