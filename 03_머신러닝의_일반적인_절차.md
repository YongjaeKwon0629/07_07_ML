# 3. 머신러닝의 일반적인 절차

머신러닝 프로젝트는 단순히 모델을 선택하고 학습시키는 과정을 넘어서, **데이터 수집부터 모델 배포 및 유지관리까지 전 주기적인 과정을 포함**합니다. 본 절에서는 머신러닝의 대표적인 워크플로우를 단계별로 설명합니다.

---

## 🧭 전체 프로세스 개요

1. 문제 정의 및 목표 설정  
2. 데이터 수집 및 이해  
3. 데이터 전처리 및 정제  
4. 특성 선택 및 엔지니어링  
5. 모델 선택 및 학습  
6. 성능 평가 및 검증  
7. 모델 배포 및 지속적 개선

---

## 1️⃣ 문제 정의

- **비즈니스 또는 연구 문제를 수치적으로 표현**
- 문제 유형 분류: 분류(Classification), 회귀(Regression), 클러스터링(Clustering) 등
- 예: “고객 이탈률을 예측” → 이진 분류 문제

---

## 2️⃣ 데이터 수집 및 이해

- 내부 데이터베이스, 외부 API, 센서, 웹 스크래핑 등 다양한 소스 활용
- 데이터 탐색적 분석(EDA) 수행: 통계량, 시각화, 이상치 파악 등

> 도구 예시: pandas, seaborn, matplotlib, Tableau 등

---

## 3️⃣ 데이터 전처리

- 결측치(Missing Value) 처리
- 이상치(Outlier) 제거 또는 대체
- 정규화(Normalization), 표준화(Standardization)
- 범주형 변수 인코딩 (One-Hot, Label Encoding 등)

---

## 4️⃣ 특성 선택 및 엔지니어링

- 주요 변수 선택: 상관계수, 모델 기반 선택, Wrapper 방법 등
- 파생 변수 생성: 날짜 → 요일, 시간대, 이진 플래그 등
- 차원 축소: PCA, t-SNE 등

---

## 5️⃣ 모델 선택 및 학습

- 문제 유형에 따라 적절한 알고리즘 선택
  - 분류: 로지스틱 회귀, SVM, 랜덤포레스트
  - 회귀: 선형 회귀, Lasso, XGBoost
  - 딥러닝: CNN, RNN, Transformer 등
- 교차 검증(Cross-Validation) 사용 권장
- 하이퍼파라미터 튜닝: Grid Search, Random Search, Optuna 등

---

## 6️⃣ 성능 평가 및 검증

- 분류: 정확도(Accuracy), 정밀도, 재현율, F1, ROC-AUC
- 회귀: RMSE, MAE, R²
- 모델 안정성 및 과적합 여부 평가
- 학습곡선(Learning Curve), 혼동 행렬, 잔차 분석 등 활용

---

## 7️⃣ 모델 배포 및 유지관리

- 배포 방법:
  - REST API 서버화 (Flask, FastAPI 등)
  - 클라우드 서비스 (AWS SageMaker, GCP AI Platform 등)
- 지속적 학습 및 성능 모니터링 필요
- 데이터 드리프트, 모델 노후화 대응 체계 수립

---

## 🧠 참고 사항

- 머신러닝 프로젝트는 **데이터 중심(data-centric)** 접근이 중요합니다.
- 초기 전처리, 특성 설계의 질이 모델 성능에 직접적으로 영향을 미칩니다.
- 실험의 재현성과 버전 관리를 위해 ML Ops 툴(Pipeline, DVC, MLflow 등) 도입 고려

---

> 다음: [4. 머신러닝 vs 전통 프로그래밍](./04_머신러닝_vs_전통_프로그래밍.md)
